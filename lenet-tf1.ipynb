{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implenting LeNet-5 using tensorflow low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import numpy.random as npr;\n",
    "import _pickle as cPickle\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.01\n",
    "imagesAsArray = np.load(\"imagesAsArray.npy\")\n",
    "labels = np.load(\"labelsVector.npy\")\n",
    "numberOfTrainingImages = 12000\n",
    "numberOfTestingImages = 3000\n",
    "numberOfLanes = 4\n",
    "imgWidth = 256\n",
    "imgHeight = 144\n",
    "neuronsInImage = imgWidth * imgHeight\n",
    "\n",
    "print(imagesAsArray.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "if (numberOfTrainingImages + numberOfTestingImages >= imagesAsArray.shape[0]):\n",
    "  print('Changed number of trainig and testing data')\n",
    "  numberOfTrainingImages = 1000\n",
    "  numberOfTestingImages = 3265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and Splitting training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawIndices = np.array(range(0,imagesAsArray.shape[0]))\n",
    "npr.shuffle(rawIndices)\n",
    "trainIndice = rawIndices[0:numberOfTrainingImages]\n",
    "testIndice = rawIndices[numberOfTrainingImages: numberOfTrainingImages + numberOfTestingImages]\n",
    "traind = imagesAsArray[trainIndice]\n",
    "trainl = labels[trainIndice]\n",
    "testd = imagesAsArray[testIndice]\n",
    "testl = labels[testIndice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class Distribution: {}'.format(trainl.sum(axis=0)))\n",
    "print('Training Data Dimension: {}'.format(traind.shape))\n",
    "print('Training Label Dimension: {}'.format(trainl.shape))\n",
    "print('Testing Data Dimension: {}'.format(testd.shape))\n",
    "print('Testing Label Dimension: {}'.format(testl.shape))\n",
    "print('EPOCHS: {}'.format(EPOCHS))\n",
    "print('BATCH_SIZE: {}'.format(BATCH_SIZE))\n",
    "print('Optimizer: SGD')\n",
    "print('Learning Rate: {}'.format(LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten/Reshape Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = traind.reshape(-1, imgHeight, imgWidth,1)\n",
    "testd = testd.reshape(-1, imgHeight, imgWidth, 1)\n",
    "print(traind.shape, testd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data tensor in NHWC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_placeholder = tf.placeholder(tf.float32,[None,imgHeight, imgWidth,1])\n",
    "label_placeholder = tf.placeholder(tf.float32,[None,numberOfLanes])\n",
    "print(data_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainFd = {data_placeholder: traind, label_placeholder: trainl }\n",
    "# testFd = {data_placeholder: testd, label_placeholder: testl }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer 1\n",
    "#### Convolution Layer with 32 fiters and a kernel size of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.nn.relu(tf.layers.conv2d(data_placeholder,6, 5,name=\"H1\"))\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling (down-sampling) with strides of 2 and kernel size of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer 2\n",
    "#### Convolution Layer with 64 filters and a kernel size of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.nn.relu(tf.layers.conv2d(a1, 16, 5,name=\"H2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling (down-sampling) with strides of 2 and kernel size of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "print(a2)\n",
    "# a2flat = tf.reshape(a2, (-1,4*4*16))\n",
    "a2flat = tf.reshape(a2, (-1,33*61*16))\n",
    "print(a2flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3 = 120\n",
    "# allocate variables\n",
    "# W3 = tf.Variable(npr.uniform(-0.01,0.01, [4*4*16,Z3]),dtype=tf.float32, name =\"W3\")\n",
    "W3 = tf.Variable(npr.uniform(-0.01,0.01, [33*61*16,Z3]),dtype=tf.float32, name =\"W3\")\n",
    "b3 = tf.Variable(npr.uniform(-0.01,0.01, [1,Z3]),dtype=tf.float32, name =\"b3\")\n",
    "# compute activations\n",
    "a3 = tf.nn.relu(tf.matmul(a2flat, W3) + b3)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z4 = 84\n",
    "# allocate variables\n",
    "W4 = tf.Variable(npr.uniform(-0.01,0.01, [Z3,Z4]),dtype=tf.float32, name =\"W4\")\n",
    "b4 = tf.Variable(npr.uniform(-0.01,0.01, [1,Z4]),dtype=tf.float32, name =\"b4\")\n",
    "# compute activations\n",
    "a4 = tf.nn.relu(tf.matmul(a3, W4) + b4)\n",
    "print(a4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alloc variables\n",
    "Z5 = numberOfLanes\n",
    "W5 = tf.Variable(npr.uniform(-0.1,0.1, [Z4,Z5]),dtype=tf.float32, name =\"W5\")\n",
    "b5 = tf.Variable(npr.uniform(-0.01,0.01, [1,Z5]),dtype=tf.float32, name =\"b5\")\n",
    "# compute activations\n",
    "logits = tf.matmul(a4, W5) + b5\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossBySample = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=label_placeholder)\n",
    "loss = tf.reduce_mean(lossBySample)\n",
    "\n",
    "nrCorrect = tf.reduce_mean(tf.cast(tf.equal (tf.argmax(logits,axis=1), tf.argmax(label_placeholder,axis=1)), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create update optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = LR)\n",
    "update = optimizer.minimize(loss) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(nrCorrect, feed_dict={data_placeholder: batch_x, label_placeholder: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    ## init all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        for offset in range(0, trainl.shape[0], BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = traind[offset:end], trainl[offset:end]\n",
    "            batch_test_x, batch_test_y = testd[offset:end], testl[offset:end]\n",
    "            trainFd = {data_placeholder: batch_x, label_placeholder: batch_y}\n",
    "            testFd = {data_placeholder: batch_test_x, label_placeholder: batch_test_y}\n",
    "            #update parameters\n",
    "            sess.run(update, feed_dict=trainFd)\n",
    "            correct, lossVal = sess.run([nrCorrect,loss], feed_dict=trainFd)\n",
    "            #testacc = sess.run(nrCorrect, feed_dict = testFd)\n",
    "            print('Epoch {}, acc={:.6f}, loss={:.6f}\\r'.format(i, float(correct), lossVal), end='')\n",
    "\n",
    "        print()\n",
    "        X_validation, y_validation = traind[::-1], trainl[::-1]\n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"Validation Accuracy = {:.6f}\".format(validation_accuracy))\n",
    "        test_accuracy = evaluate(testd, testl)\n",
    "        print(\"Test Accuracy = {:.6f}\".format(test_accuracy))\n",
    "        print()\n",
    "    \n",
    "#     test_accuracy = evaluate(testd, testl)\n",
    "#     print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
